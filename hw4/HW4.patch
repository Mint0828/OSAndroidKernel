diff --git a/include/linux/sched.h b/include/linux/sched.h
index ff6bb0f..6a0a691 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -39,6 +39,7 @@
 #define SCHED_BATCH		3
 /* SCHED_ISO: reserved but not implemented yet */
 #define SCHED_IDLE		5
+#define SCHED_MYCFS		6
 /* Can be ORed in to make sure the process is reverted back to SCHED_NORMAL on fork */
 #define SCHED_RESET_ON_FORK     0x40000000
 
@@ -1232,12 +1233,12 @@ struct sched_entity {
 #endif
 };
 
+
 struct sched_rt_entity {
 	struct list_head run_list;
 	unsigned long timeout;
 	unsigned int time_slice;
 	int nr_cpus_allowed;
-
 	struct sched_rt_entity *back;
 #ifdef CONFIG_RT_GROUP_SCHED
 	struct sched_rt_entity	*parent;
@@ -1248,6 +1249,14 @@ struct sched_rt_entity {
 #endif
 };
 
+// PJ: populate it with entries similar to struct_entity
+struct sched_mycfs_entity{
+        struct sched_mycfs_entity	*parent;
+        unsigned int time_slice;
+        struct rb_node		run_node;
+		u64			exec_start;
+		u64			vruntime;
+};
 /*
  * default timeslice is 100 msecs (used only for SCHED_RR tasks).
  * Timeslices get refilled after they expire.
@@ -1619,6 +1628,7 @@ struct task_struct {
 #ifdef CONFIG_HAVE_HW_BREAKPOINT
 	atomic_t ptrace_bp_refcnt;
 #endif
+	struct sched_mycfs_entity mycfs_se;
 };
 
 /* Future-safe accessor for struct task_struct's cpus_allowed. */
diff --git a/kernel/sched/Makefile b/kernel/sched/Makefile
index 3ede7d9..39c672d 100644
--- a/kernel/sched/Makefile
+++ b/kernel/sched/Makefile
@@ -11,7 +11,7 @@ ifneq ($(CONFIG_SCHED_OMIT_FRAME_POINTER),y)
 CFLAGS_core.o := $(PROFILING) -fno-omit-frame-pointer
 endif
 
-obj-y += core.o clock.o idle_task.o fair.o rt.o stop_task.o sched_avg.o
+obj-y += core.o clock.o idle_task.o mycfs.o fair.o rt.o stop_task.o sched_avg.o
 obj-$(CONFIG_SMP) += cpupri.o
 obj-$(CONFIG_SCHED_AUTOGROUP) += auto_group.o
 obj-$(CONFIG_SCHEDSTATS) += stats.o
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 1cee48f..7e05631 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -4063,6 +4063,12 @@ __setscheduler(struct rq *rq, struct task_struct *p, int policy, int prio)
 		p->sched_class = &rt_sched_class;
 	else
 		p->sched_class = &fair_sched_class;
+
+	if(policy == SCHED_MYCFS)
+	{
+		p->sched_class = &mycfs_sched_class;
+		printk("process %d is assigned mycfs scheduler\n",p->pid);
+	}
 	set_load_weight(p);
 }
 
@@ -4107,7 +4113,7 @@ recheck:
 
 		if (policy != SCHED_FIFO && policy != SCHED_RR &&
 				policy != SCHED_NORMAL && policy != SCHED_BATCH &&
-				policy != SCHED_IDLE)
+				policy != SCHED_IDLE && policy!= SCHED_MYCFS)
 			return -EINVAL;
 	}
 
@@ -4783,10 +4789,13 @@ SYSCALL_DEFINE1(sched_get_priority_max, int, policy)
 		ret = MAX_USER_RT_PRIO-1;
 		break;
 	case SCHED_NORMAL:
+	case SCHED_MYCFS:
 	case SCHED_BATCH:
 	case SCHED_IDLE:
 		ret = 0;
 		break;
+
+
 	}
 	return ret;
 }
@@ -4804,6 +4813,7 @@ SYSCALL_DEFINE1(sched_get_priority_min, int, policy)
 
 	switch (policy) {
 	case SCHED_FIFO:
+	case SCHED_MYCFS:
 	case SCHED_RR:
 		ret = 1;
 		break;
diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index fc60d5b..d240ab2 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -5536,7 +5536,7 @@ static unsigned int get_rr_interval_fair(struct rq *rq, struct task_struct *task
  * All the scheduling class methods:
  */
 const struct sched_class fair_sched_class = {
-	.next			= &idle_sched_class,
+	.next			= &mycfs_sched_class,
 	.enqueue_task		= enqueue_task_fair,
 	.dequeue_task		= dequeue_task_fair,
 	.yield_task		= yield_task_fair,
diff --git a/kernel/sched/mycfs.c b/kernel/sched/mycfs.c
new file mode 100644
index 0000000..fe0eeee
--- /dev/null
+++ b/kernel/sched/mycfs.c
@@ -0,0 +1,76 @@
+#include <linux/sched.h>
+//#include "mycfs.h"
+#include "sched.h"
+
+
+
+
+
+static void dequeue_task_mycfs(struct rq *rq, struct task_struct *prev,int flags)
+{
+	dec_nr_running(rq);
+}
+
+static void enqueue_task_mycfs(struct rq *rq, struct task_struct *p, int flags)
+{
+	inc_nr_running(rq);
+
+}
+//this will be the big one to implement!!!
+static struct task_struct *pick_next_task_mycfs(struct rq *rq)
+{
+	struct task_struct *stop = rq->stop;
+
+	if (stop && stop->on_rq)
+		return stop;
+
+
+	return NULL;
+}
+
+
+
+
+
+
+static void put_prev_task_mycfs(struct rq *rq, struct task_struct *prev)
+{
+	//printk("put_prev_task_mycfs\n");
+}
+
+static void yield_task_mycfs(struct rq *rq)
+{
+}
+
+static int select_task_rq_mycfs(struct task_struct *p, int sd_flag, int wake_flags)
+{
+
+	return task_cpu(p); 
+	
+}
+
+static void task_tick_mycfs(struct rq *rq, struct task_struct *curr, int queued)
+{
+}
+
+static void task_fork_mycfs(struct task_struct *p)
+{
+}
+
+const struct sched_class mycfs_sched_class = {
+	.next = &idle_sched_class,
+	.dequeue_task	= dequeue_task_mycfs,
+	.pick_next_task = pick_next_task_mycfs,
+	.enqueue_task = enqueue_task_mycfs,
+	.put_prev_task	= put_prev_task_mycfs,
+	.yield_task		= yield_task_mycfs,
+	#ifdef CONFIG_SMP
+	.select_task_rq		= select_task_rq_mycfs,
+	#endif
+	.task_tick		= task_tick_mycfs,
+	.task_fork		= task_fork_mycfs,
+};
+
+
+
+
diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h
index 5370bcb..9f27b17 100644
--- a/kernel/sched/sched.h
+++ b/kernel/sched/sched.h
@@ -273,6 +273,19 @@ struct cfs_rq {
 #endif /* CONFIG_FAIR_GROUP_SCHED */
 };
 
+//PJ: to be populated with many fields
+struct mycfs_rq 
+{
+	unsigned long nr_running, h_nr_running;
+	u64 min_vruntime;
+#ifndef CONFIG_64BIT
+	u64 min_vruntime_copy;
+#endif
+	struct rb_root tasks_timeline;
+	struct rb_node *rb_leftmost;
+	struct sched_entity *curr, *next, *last, *skip;
+};
+
 static inline int rt_bandwidth_enabled(void)
 {
 	return sysctl_sched_rt_runtime >= 0;
@@ -465,6 +478,7 @@ struct rq {
 #ifdef CONFIG_SMP
 	struct llist_head wake_list;
 #endif
+	struct mycfs_rq mycfs;
 };
 
 static inline int cpu_of(struct rq *rq)
@@ -856,6 +870,7 @@ enum cpuacct_stat_index {
 extern const struct sched_class stop_sched_class;
 extern const struct sched_class rt_sched_class;
 extern const struct sched_class fair_sched_class;
+extern const struct sched_class mycfs_sched_class;
 extern const struct sched_class idle_sched_class;
 
 
